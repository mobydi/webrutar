# Сопроводительная записка #

### Задание ###

Написать программу, подсчитывающую для пользователя сети “ВКонтакте” зависимость между объëмом текста в его собственных записях на стене и количеством “лайков”, которое они получили. Результат отобразить на графике, помимо этого разместить ссылку на наиболее популярную запись.
Программа должна взаимодействовать с пользователем через веб-интерфейс.
Пользователь может запросить отчëт только по собственному аккаунту.
Результат становится доступен заказчику отчëта через размещение в единой ленте, доступной всем посетителям сайта.
 
Система должна быть развëрнута на платформе Azure. При написании кода необходимо использовать MVC и EF.
Программа должна работать стабильно в том числе и при существенной нагрузке.
В качестве решения необходимо предоставить URL работающей версии, исходный код и сопроводительную записку.


### Архитектура приложения ###

API Vkontakte принимает ограниченное количество запросов в секунду: “Если приложение установило меньше 10 000 человек, то можно совершать 5 запросов в секунду, до 100 000 – 8 запросов, до 1 000 000 – 20 запросов, больше 1 млн. – 35 запросов в секунду.“ 

Статистика, которую мы считаем - не требует никаких вычислительный ресурсов.

Соответственно, надо было выбрать архитектуру, которая продолжает с заданными ограничениями медленно вытаскивать посты пользователей и масштабируется по числу пользователей.

![alt text](https://acomdpsstorage.blob.core.windows.net/dpsmedia-prod/azure.microsoft.com/en-us/documentation/articles/fundamentals-introduction-to-azure/20150514052253/includes/intro-to-azure/cloudservicesintronew.png)

Web & Worker общаются между собой через очередь. Worker разбивает вызовы к vk api на порции и рекурсивно отдает себе задания через ту же очередь.

Если бы было больше времени и были бы более серьезные лимиты у VK API, то можно было бы сделать архитектуру с акторами AKKA.NET/Orleans. В такой абстракции, можно более гибко регулировать количество запросов в секунду в соответствии с разными настройками даже с масштабируемыми воркерами, гибко обрабатывать данные и строить отчеты, если они вдруг станут тяжеловесными.

### Масштабирование и ограничения ###

Единственное, что в текущей задаче требуется масштабировать - это большое количество заходящих на ресурс пользователей, т.е. сам веб-сервер. Из-за низкой пропускной способности VK API масштабировать воркер, который достает посты со стены - нет смысла.

MessageQueue гарантирует at least once доставку сообщений. Поэтому был выбран формат хранения данных в стиле CRDT (не смотря на то, что у нас consistent база данных, такой формат позволяет избежать проблем с конкурирующими изменениями). Данные об записях со стены (длина + like + post_id) хранятся в формате запись - строчка, без уникального ключа по post_id. При построении отчета делается Distinct по post_id. 

То же самое с записями про самую популярную запись пользователя. Мы никогда ее не обновлем, а всегда добавляем новую строчку в таблицу. Это позволяет избежать проблем с возможными конфликтами при параллельном изменении этой записи несколькими воркерами (хотя сейчас всегда один воркер на один отчет).

Для маштабирования веб-сервера надо настроить Session Cache (для хранения web session - авторизация, все остальное берется из базы). Это вопрос строчек в конфиге.

### Ограничения реалиазции ###

* Пользователь ВК может добавить сообщения во время процессинга. В текущей реализации нет хешей обработанных сообщений.
* Сбор данных при первой ошибке прекращает работу. Можно сделать автоматический retry или еще какую-то обработку ошибок.
* Запускаем только один вокер на пользовательский отчет. Т.е. если у пользователя 1000 записей (лимит VK 100 записей за раз, у нас 90), то произойдет 10 последовательных запросов. При этом в текущей архитектуре никаких проблем с запуском параллельных и даже дублирующихся воркеров нет.
* Маштабировать вокрер сейчас нельзя и не имеет смысла, т.к. VK Api ограничивает количество запросов в секунду (см. ранее замечание про AKKA).
* Выборка данных для одного отчета тоже не параллелится. Но эта функциональность реализуется достаточно просто с использованием CRDT: при скачивании очередного куска данных, мы записываем в базу соответствующую запись (n_start, n_end). Периодически проверяем, что в базе лежат все интервалы, тогда вся большая задача закончена. Даже если остались дублирующие задачи,  это никак не повлияет на результат (мы уже умеем не обращать внимание на все дублирующиеся данные). Опять же с акторами, когда у нас все задачи в руках, такой подход реализуется более красиво.
* Логирование минимально
* Тесты - за рамками задания, т.к. нет практически никакой логики. А то что есть можно тестировать только через mock, тестовые базы данных - это достаточно долгое по времени развлечение. Поэтому писались тесты только по-необходимости, на то, что делалось руками: vk api parser 
* Никакой верстки. График сделан в лоб, выглядит уныло.
* После того, как данные о записях пользователя собраны, их можно удалить, сгенерировав один blob для отчета, и потом этот блоб показыать, или строить из него график и т.д. Это сильно позволит сэкономить на чтениях из базы данных.

 